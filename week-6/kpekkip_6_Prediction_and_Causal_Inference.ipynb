{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uY87IsNQpVZ"
      },
      "source": [
        "# Week 6 - Prediction & Causal Inference\n",
        "\n",
        "Last week, we explored (supervised) text classification, where we train a model to learn associations between text and some classification or value connected with it (e.g., what distinguishes a winning argument before the Supreme Court; can we extend our judgment regarding what documents are relevant to my thesis project to all of Google News; etc.) Classification often uses a representative sample of text about which we want to make inferences and then we use machine learning to learn \"true\" assignments and classify the rest.\n",
        "\n",
        "This week, we explore two different types of inferences to out-of-sample populations. _Prediction_ involves our reasoned expectation regarding an unobserved state of the world, given the world in which we live and on which we have trained our prediction algorithm. Often this prediction is about the future world. We don't expect the U.S. Congress to talk about the identical things today and tomorrow, but today should contain some useful information. by contrast _causal inference_ poses the related by distinct challenge of our reasoned expectations regarding an unobserved state of the world IF we intervene in some way. In other words, what does the intervention cause, and how can we predict it to change the world. Causality has a deeply contested history in social science and philosophy, but it usually involves an \"if,\" a difference between two counterfactual worlds, one where an event occurs and one where it doesn't.\n",
        "\n",
        "Causal questions in text analysis may place the text in one or more of many positions we explore below: as cause, effect, confounder, mediator (or moderator), or collider. For example, assuming that everything spoken can be transcribed into text, saying something mean might hurt someone's feelings (text as cause). Doing something mean might cause someone to say something angry (text as effect). Apologizing might change the influence of doing something mean (text as mediator/moderator). A compliment might obscure the effect of doing something mean (text as confounder). And yelling something audaciously mean might yield a loud, emotional response, which both influence the likelihood that the interaction was recorded and subjected to analysis (text as collider). As you can see, in a single conversation, text can play all of these roles. Why do we care about cause and effect with text? Because while words appear to exert power in the world, which words spoken under what circumstances by whom? Causal analysis attempts to get at the question, if _X_ was written or spoken, _Y_ would happen."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U git+git://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03YSdjSeLUfE",
        "outputId": "91c9f02f-61d7-4671-97b8-1cb44954391f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+git://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git\n",
            "  Cloning git://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git to /tmp/pip-req-build-gguf6wuj\n",
            "  Running command git clone -q git://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git /tmp/pip-req-build-gguf6wuj\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lucem-illud==8.0.1) (1.21.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from lucem-illud==8.0.1) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from lucem-illud==8.0.1) (1.3.5)\n",
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from lucem-illud==8.0.1) (7.1.2)\n",
            "Collecting pdfminer2\n",
            "  Downloading pdfminer2-20151206-py2.py3-none-any.whl (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 7.4 MB/s \n",
            "\u001b[?25hCollecting GitPython\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 43.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from lucem-illud==8.0.1) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lucem-illud==8.0.1) (1.4.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from lucem-illud==8.0.1) (0.11.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lucem-illud==8.0.1) (1.0.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from lucem-illud==8.0.1) (3.2.5)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from lucem-illud==8.0.1) (3.6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from lucem-illud==8.0.1) (3.2.2)\n",
            "Collecting pyanno3\n",
            "  Downloading pyanno3-2.0.2.tar.gz (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from lucem-illud==8.0.1) (4.6.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from lucem-illud==8.0.1) (0.10.1)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.21.6-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 53.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from lucem-illud==8.0.1) (2.6.3)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting speechrecognition\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8 MB 128 kB/s \n",
            "\u001b[?25hCollecting pysoundfile\n",
            "  Downloading PySoundFile-0.9.0.post1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from lucem-illud==8.0.1) (0.18.3)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from lucem-illud==8.0.1) (5.5.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from lucem-illud==8.0.1) (2.2.4)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting botocore<1.25.0,>=1.24.6\n",
            "  Downloading botocore-1.24.6-py3-none-any.whl (8.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.5 MB 21.6 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.1-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 40.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.6->boto3->lucem-illud==8.0.1) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.6->boto3->lucem-illud==8.0.1) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->lucem-illud==8.0.1) (5.2.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython->lucem-illud==8.0.1) (3.10.0.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->lucem-illud==8.0.1) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->lucem-illud==8.0.1) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->lucem-illud==8.0.1) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->lucem-illud==8.0.1) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->lucem-illud==8.0.1) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->lucem-illud==8.0.1) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->lucem-illud==8.0.1) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->lucem-illud==8.0.1) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->lucem-illud==8.0.1) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lucem-illud==8.0.1) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lucem-illud==8.0.1) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lucem-illud==8.0.1) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->lucem-illud==8.0.1) (2018.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->lucem-illud==8.0.1) (0.7.0)\n",
            "Collecting traits\n",
            "  Downloading traits-6.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (5.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.1 MB 35.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.7/dist-packages (from pysoundfile->lucem-illud==8.0.1) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=0.6->pysoundfile->lucem-illud==8.0.1) (2.21)\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from python-docx->lucem-illud==8.0.1) (4.2.6)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 60.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->lucem-illud==8.0.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->lucem-illud==8.0.1) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->lucem-illud==8.0.1) (3.0.4)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->lucem-illud==8.0.1) (2021.11.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->lucem-illud==8.0.1) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->lucem-illud==8.0.1) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lucem-illud==8.0.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lucem-illud==8.0.1) (1.1.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy->lucem-illud==8.0.1) (4.62.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->lucem-illud==8.0.1) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->lucem-illud==8.0.1) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->lucem-illud==8.0.1) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->lucem-illud==8.0.1) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->lucem-illud==8.0.1) (1.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->lucem-illud==8.0.1) (0.9.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->lucem-illud==8.0.1) (3.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->lucem-illud==8.0.1) (2.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->lucem-illud==8.0.1) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->lucem-illud==8.0.1) (4.11.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->lucem-illud==8.0.1) (3.7.0)\n",
            "Building wheels for collected packages: lucem-illud, pyanno3, python-docx\n",
            "  Building wheel for lucem-illud (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lucem-illud: filename=lucem_illud-8.0.1-py3-none-any.whl size=34971 sha256=c1851652428bbfd247714a836951fd4c65df4cddf535604e8f552648acf75b43\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vrqjznwr/wheels/a5/6a/0f/ddf40c68215bc4b072c455caa6a08e0031c92187c93a1b5a81\n",
            "  Building wheel for pyanno3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyanno3: filename=pyanno3-2.0.2-py3-none-any.whl size=116978 sha256=6338206041276e2d28156073df8d9f3ba0407b8f3aa3033d2d5f2a9e71ae97c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/eb/a9/d9c212d9388cde6cf3ee6edd7aa3891624bca58b24d9c26c76\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184507 sha256=7f0d2c28e76bc346d6b544426687f5ff2cefcef2a2da97de81fd36c8586d94dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
            "Successfully built lucem-illud pyanno3 python-docx\n",
            "Installing collected packages: urllib3, jmespath, smmap, botocore, traits, s3transfer, gitdb, speechrecognition, python-docx, pysoundfile, pydub, pyanno3, pdfminer2, GitPython, boto3, lucem-illud\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.27 boto3-1.21.6 botocore-1.24.6 gitdb-4.0.9 jmespath-0.10.0 lucem-illud-8.0.1 pdfminer2-20151206 pyanno3-2.0.2 pydub-0.25.1 pysoundfile-0.9.0.post1 python-docx-0.8.11 s3transfer-0.5.1 smmap-5.0.0 speechrecognition-3.8.1 traits-6.3.2 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ME1FucyLQpVc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "25991156-009d-4736-cd1e-78f634e8bfa8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-81f1a070bb56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Pipelines to add text-based quantiative variables for regressions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# We have a lot of features, so let's set Pandas to show all of them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "#Special module written for this class\n",
        "#This provides access to data and to helper functions from previous weeks\n",
        "#Make sure you update it before starting this notebook\n",
        "import lucem_illud #pip install -U git+git://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git\n",
        "\n",
        "#All these packages need to be installed from pip\n",
        "import requests #For getting files\n",
        "import zipfile #For managing zips\n",
        "import numpy as np #For arrays\n",
        "import scipy as sp #For some stats\n",
        "import pandas as pd #Gives us DataFrames\n",
        "import numpy as np #Math and matrices\n",
        "import matplotlib.pyplot as plt #For graphics\n",
        "\n",
        "# statsmodels is a popular Python statistics package\n",
        "import statsmodels.api as sm\n",
        "# Let's also import its graphics module\n",
        "import statsmodels.graphics.api as smg\n",
        "# And the mediation module\n",
        "from statsmodels.stats.mediation import Mediation\n",
        "\n",
        "# Pipelines to add text-based quantiative variables for regressions\n",
        "from transformers import pipeline\n",
        "\n",
        "# We have a lot of features, so let's set Pandas to show all of them.\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fvys_NpQpVe"
      },
      "source": [
        "# Prediction\n",
        "We can make predictions about a range of different text 'populations'. We can use texts in English to predict their translations in French. We can use newspaper articles from 2012 to 2022 to forecast the contents of 2023 newspaper articles (e.g., a [time series](https://en.wikipedia.org/wiki/Time_series)). Or we can \"nowcast\" by using real-time social information such as Tweets to predict when an important event is happening, such as a riot.\n",
        "\n",
        "If we don't have any information about how the new population will vary from the population we modeled, then prediction is implemented in the same way as in-sample inference. E.g., if you have a categorization of 2022 emails as spam or ham, you could predict whether 2023 emails are spam the same way you predicted 2022 emails. On the other hand, if you have new information, such as a trend beginning in December 2022 for spam emails to have \"Urgent:\" in the subject line, your 2023 prediction may differ by putting more weight on that indicator relative to others.\n",
        "\n",
        "In this way, prediction is similar to the classifications we performed last last week, incorporating multidimensional trends (e.g., time, place, source) learnable from your current corpus. We encourage you to think more about this if you are interested in predicting the future of your corpus!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R72x--PiQpVf"
      },
      "source": [
        "## <font color=\"red\">*Exercise 1*</font>\n",
        "\n",
        "<font color=\"red\">Describe 2 separate predictions relevant to your project and associated texts, which involve predicting text that has not been observed based on patterns that have. Then, in a single, short paragraph, describe a research design through which you could use textual features and the tools of classification and regression to evaluate these predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First prediction: I hypothesize that the party identity of a given member of the German Bundestag predicts the sentiment of a speech if the speech is about East Germany or the former German Democratic Republic.\n",
        "\n",
        "Second prediction: Relatedly, I hypothesize that the type and location of electoral district of a given member of the Bundestag predicts the sentiment of a speech if the speech is about East Germany or the former German Democratic Republic.\n",
        "\n",
        "Research design: To test for these hypothesis, I would train a machine learning algorithm to classify speeches in the German parliament as either unrelated to the GDR, positively referencing the GDR, or negatively referencing the GDR. In a second step, I would construct a linear regression model, regressing party identity, district type and/or district location on the sentiment of the speeches. I expect a positive association between Die Linke / AfD party membership and positive references towards the GDR. I also expect a positive association between East German rural district types and positive references towards the GDR in speeches."
      ],
      "metadata": {
        "id": "ul6pXhkDo_CM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqyWdnHUQpVf"
      },
      "source": [
        "# Text in causal inference\n",
        "\n",
        "In causal inference, we are interested in the effect of a _treatment_ on an _outcome_. There are five types of variables that could be directly involved in our causal model, and any could be a text variable. This figure from [Keith et al. 2020](https://aclanthology.org/2020.acl-main.474.pdf) concisely shows the five positions for variables in acyclic (i.e., no arrows flow back into themselves) causal inference: treatment, mediator, outcome, confounder, and collider.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/UChicago-Computational-Content-Analysis/Homework-Notebooks/main/week-6/img/causal_diagram.png\" alt=\"https://raw.githubusercontent.com/UChicago-Computational-Content-Analysis/Homework-Notebooks/main/week-6/img/causal_diagram.png\" style=\"width:500px\">\n",
        "\n",
        "\"Text as treatment\" means the effect of text on other variables. For example, how does the news coverage of a politician affect their election chance? How does the sentiment of a Reddit post affect its upvotes?\n",
        "\n",
        "Whether we're interested in text as treatment, mediator, outcome, or confounder, we have at our disposal the same causal inference strategies used with other forms of data, such as matching, difference in difference, regression discontinuity, and instrumental variables. Each of these methods usually gives you a more precise conditional identification of the causal influence than regressing an effect on a singular (purported) cause. For example, one of the readings for this week, [Saha 2019](https://doi.org/10.1145/3292522.3326032), uses propensity score matching, which is a straightforward method that works on most datasets (see Professor Gary King on [coarsened exact matching](https://www.youtube.com/watch?v=tvMyjDi4dyg)). For this assignment, we do not detail each of these causal strategies, but note several courses at UChicago that introduce these methods, as well as online textbooks (e.g., Scott Cunningham's [Causal Inference: The Mixtape](https://mixtape.scunning.com/)).\n",
        "\n",
        "You can do causal inference on any sort of text data as long as you have a plausible _identification_ strategy, meaning an argument that you can correctly identify a causal effect if one exists using your data and analysis. For example, if you have a data from a randomized controlled trial (RCT) where you intervene randomly with some treatment, you can identify a causal effect with relative ease. Text exhibits a wide array of dependencies making unconditional randomization impossible, but we will attempt strategies that approach it. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPGV789sQpVg"
      },
      "source": [
        "# Text as treatment and outcome\n",
        "\n",
        "To illustrate text as treatment and outcome, we will analyze a dataset of internet arguments. We have 8,895 pairs of comments, where one person makes a statement and the other responds. Our research question is thus: _How does the text of the first commenter affect the text of the respondent?_\n",
        "\n",
        "The data comes from the [Internet Argument Corpus](https://nlds.soe.ucsc.edu/iac). Let's load the data and take a look."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IS3ZZ1d8QpVh"
      },
      "outputs": [],
      "source": [
        "url = 'http://nldslab.soe.ucsc.edu/iac/iac_v1.1.zip'\n",
        "\n",
        "req = requests.get(url)\n",
        "\n",
        "filename = url.split('/')[-1]\n",
        "with open(filename,'wb') as output_file:\n",
        "    output_file.write(req.content)\n",
        "print('Downloaded file: ' + url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1RpornTQpVh"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile('iac_v1.1.zip') as z:\n",
        "   with z.open('iac_v1.1/data/fourforums/annotations/mechanical_turk/qr_averages.csv') as f:\n",
        "      qr = pd.read_csv(f)\n",
        "\n",
        "   with z.open('iac_v1.1/data/fourforums/annotations/mechanical_turk/qr_meta.csv') as f:\n",
        "      md = pd.read_csv(f)\n",
        "\n",
        "# columns = ['key', 'nicenasty', 'questioning-asserting', 'negotiate-attack', 'fact-feeling']\n",
        "# qr_sub = qr[columns]\n",
        "# qr_sub = qr\n",
        "\n",
        "pairs = qr.merge(md, how='inner', on='key')\n",
        "pairs = pairs[~pairs.quote_post_id.isnull() & ~pairs.response_post_id.isnull()]\n",
        "pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYFTtHFdQpVi"
      },
      "source": [
        "Note that each comment and response were annotated by workers on Amazon Mechanical Turk, which we piloted last week. Variables like \"agree-disagree\" are the averages of annotations made by workers on Mechanical Turk on an 11-point Likert scale (-5 to 5) using a slider. Workers were asked questions, and then had the opportunity to note whether or not their were \"unsure\" about their assessment (Boolean - Y/N):\n",
        "\n",
        "* __agree/disagree__ (Boolean -- Y/N): Does the respondent agree (0) OR disagree (1) with the prior post?\n",
        "* __sarcasm__ (Boolean -- Y/N): Is the respondent using sarcasm (1 - Y; 0 - N)?\n",
        "* __fact/feeling__  (-5 to 5): Is the respondent attempting to make a fact based argument (-5) OR appealing to feelings and emotions (+5)?\n",
        "* __attack/insult__ (-5 to 5): Is the respondent being supportive/respectful (-5) OR are they attacking/insulting in their writing (+5)?\n",
        "* __nice/nasty__ (-5 to 5): Is the respondent attempting to be nice (-5) OR is their attitude fairly nasty (+5)?\n",
        "* __audience__ (-5 to 5): Is the respondent's arguments intended more to be interacting directly with the original poster (-5) OR with a wider audience (+5)?\n",
        "* __undercutting__ (-5 to 5): Is the argument of the respondent targeted at the entirety of the original poster's argument (-5) OR is the argument of the respondent targed at a more specific idea within the post (+5)?\n",
        "* __negotiate/attack__ (-5 to 5): Does the respondent seem to have an argument of their own (-5) OR is the respondent simply attacking the original poster's argument (+5)?\n",
        "* __question/assert__ (-5 to 5): Is the respondent questioning the original poster (-5) OR is the respondent asserting their own ideas (+5)?\n",
        "\n",
        "Unfortunately the dataset only has the \"response\" annotated, not the original \"quote.\" However, some \"responses\" in this dataset are also \"quotes,\" meaning we can form triples of quote-response-response. Let's self-merge this dataframe to get these \"r1\" and \"r2\" pairs where both texts have annotations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GY_iXAZGQpVi"
      },
      "outputs": [],
      "source": [
        "# Self-merge where the 'response' matches another 'quote' in the DataFrame\n",
        "triples = pairs.merge(pairs,left_on='response',right_on='quote',how='inner',suffixes=('_r1','_r2'))\n",
        "\n",
        "# Rename and reorder columns\n",
        "triples = triples.rename(columns={'quote_r1':'quote', 'quote_r2':'response1', 'response_r2':'response2'})\n",
        "triples = triples.drop(columns=['response_r1'])\n",
        "front_columns = [\n",
        "                 'quote','response1','response2','attack_r1','fact-feeling_r1','nicenasty_r1','sarcasm_r1',\n",
        "                 'agreement_r2'\n",
        "                ]\n",
        "triples = triples.dropna(subset=front_columns)\n",
        "triples = triples[front_columns].join(triples.drop(columns=front_columns))\n",
        "\n",
        "# Display triples\n",
        "triples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBRRQ8zVQpVj"
      },
      "source": [
        "Now we have 1,346 triples of quote-response1-response2, several text variables of response1 (e.g., \"Is the respondent using sarcasm?\") that may predict the agreement of response2. In other words: _Does a sarcastic comment lead to more agreement?_ Of course, as with almost all observational data, there are a number of confounders that make our identification difficult, but for now, let's explore how to run a simple regression in Python of agreement_r2 (dependent variable, commonly known as Y) on sarcasm_r1. Fortunately, we do have a strong case for identifying the direction of causality: Because response1 comes before response2, we can rule out the possibility that response2 affects response1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bj-_LbKvQpVj"
      },
      "outputs": [],
      "source": [
        "# We build an Ordinary Least Squares (OLS) model of agreement_r2 on sarcasm_r1.\n",
        "# The function sm.add_constant() adds an intercept term to the regression (e.g., b in y = ax + b)\n",
        "y = triples['agreement_r2']\n",
        "X_cols = ['sarcasm_r1']\n",
        "X = sm.add_constant(triples[X_cols])\n",
        "\n",
        "lm1 = sm.OLS(y,X).fit()\n",
        "lm1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdlDoRqZQpVj"
      },
      "source": [
        "The p-value for sarcasm_r1 is 0.855, which means that we fail to reject the null hypothesis that there is no effect of sarcasm on agreement. However, we have other variables that may be confounding the effect of pure \"attack\" or pure \"sarcasm.\" Let's try adding 3 other annotations to the regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOSmnyT0QpVj"
      },
      "outputs": [],
      "source": [
        "y = triples['agreement_r2']\n",
        "X_cols = ['attack_r1','fact-feeling_r1','nicenasty_r1','sarcasm_r1']\n",
        "X = sm.add_constant(triples[X_cols])\n",
        "\n",
        "lm2 = sm.OLS(y,X).fit()\n",
        "lm2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhOdpMmtQpVk"
      },
      "source": [
        "The condition number (bottom-right of the output above) is 12.8, indicating high correlations between our predictors or collinearity. This is one of many issues to look out for when running regressions. Let's take a look at the correlations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNluMsABQpVk"
      },
      "outputs": [],
      "source": [
        "corr_matrix = np.corrcoef(triples[X_cols].T)\n",
        "smg.plot_corr(corr_matrix, xnames=X_cols)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll_87HXHQpVk"
      },
      "source": [
        "That's very high correlation between attack_r1 and nicenasty_r1 (recall that nasty is +5...this should be no surprise)! We found a significant effect of attack_r1, but not of nicenasty_r1. If we remove attack_r1 from the model, do you think nicenasty_r1 will be significant?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5qGLnLPQpVk"
      },
      "outputs": [],
      "source": [
        "y = triples['agreement_r2']\n",
        "X_cols = ['fact-feeling_r1','nicenasty_r1','sarcasm_r1']\n",
        "X = sm.add_constant(triples[X_cols])\n",
        "\n",
        "lm2 = sm.OLS(y,X).fit()\n",
        "lm2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AW3DkH2QpVk"
      },
      "source": [
        "Yes, it is! And the t-value is even larger (i.e., stronger evidence of an effect). With this new regression model, we see a significant effect from attack_r1/nicenasty_r1 and sarcasm_r1, indicating both of these dimensions affect whether the response2 agrees with response1. Note that the coefficients are both positive: For attack_r1/nicenasty_r1, this means that a more \"nasty\" comment led to more disagreement, and for sarcasm_r1, this means that a more sarcasistic comment led to more disagreement.\n",
        "\n",
        "For good measure, we can add other variables ourselves, such as sentiment and the character length of the comment. The length may be particularly important based on how it affects the annotations of Mechanical Turk workers. For example, as we were skimming through the data, it seemed like shorter comments were being rated as more nasty. For sentiment, let's use the convenient BERT pipeline we used last week and which we will detail and theorize in weeks to come."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOLXf1usQpVl"
      },
      "outputs": [],
      "source": [
        "triples['length_r1'] = triples['response1'].apply(lambda x: len(x))\n",
        "triples['length_r2'] = triples['response2'].apply(lambda x: len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IC00B58dQpVl"
      },
      "outputs": [],
      "source": [
        "sentiment = pipeline(\"sentiment-analysis\")\n",
        "result = sentiment(\"I hate you\")[0]\n",
        "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xicDSe93QpVl"
      },
      "source": [
        "This version of BERT is built only for texts of up to 512 tokens, so for comments longer than that, we truncate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTro9KRtQpVl"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "triples['sentiment_r1'] = triples['response1'].apply(lambda x: sentiment(x[:512])[0]['score'])\n",
        "triples['sentiment_r2'] = triples['response2'].apply(lambda x: sentiment(x[:512])[0]['score'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajy4lFLbQpVl"
      },
      "outputs": [],
      "source": [
        "y = triples['agreement_r2']\n",
        "X_cols = ['fact-feeling_r1','nicenasty_r1','sarcasm_r1','length_r1','sentiment_r1']\n",
        "X = sm.add_constant(triples[X_cols])\n",
        "\n",
        "lm2 = sm.OLS(y,X).fit()\n",
        "lm2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crpjS4rmQpVm"
      },
      "outputs": [],
      "source": [
        "corr_matrix = np.corrcoef(triples[X_cols].T)\n",
        "smg.plot_corr(corr_matrix, xnames=X_cols)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6UoSjxNQpVm"
      },
      "source": [
        "The condition number is reasonably high, but our correlatons do not seem too strong. Overall, our finding of significant effects for attack_r1/nasty_r1 and sarcasm_r1 persists with these new controls! This sort of robustness or sensitivity analysis is important for making sure your finding is compelling to yourself and to your audience. Consider doing other robustness checks, such as standardizing these variables before running the regression or adding [robust standard errors](https://en.wikipedia.org/wiki/Heteroscedasticity-consistent_standard_errors). (To be clear, the analysis above would likely not be sufficient as proof of a causal effect for a peer-reviewed journal; you would likely need a more conditional approach using matching, instruments or differences in differences.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go07xp2LQpVm"
      },
      "source": [
        "## <font color=\"red\">*Exercise 2*</font>\n",
        "\n",
        "<font color=\"red\">Propose a simple causal model in your data, or a different causal model in the annotated Internet Arguments Corpus (e.g., a different treatment, a different outcome), and test it using a linear or logistic regression model. If you are using social media data for your final project, we encourage you to classify or annotate a sample of that data (either compuationally or with human annotators) and examine the effect of texts on replies to that text (e.g., Reddit posts on Reddit comments, Tweets on Twitter replies, YouTube video transcripts on YouTube comments or ratings). You do not need to make a graph of the causal model, but please make it clear (e.g., \"X affects Y, and C affects both X and Y.\").\n",
        "    \n",
        "<font color=\"red\">Also consider using the [ConvoKit datasets](https://convokit.cornell.edu/documentation/datasets.html)! Anytime there is conversation, there is an opportunity to explore the effects of early parts of the conversation on later parts. We will explore this further in Week 8 on Text Generation and Conversation.\n",
        "    \n",
        "<font color=\"red\">***Stretch*** (not required): Propose a more robust identification strategy using either matching, difference in difference, regression discontinuity, or an instrumental variable. Each of these methods usually gives you a more precise identification of the causal effect than a unconditional regression. Scott Cunningham's [Causal Inference: The Mixtape](https://mixtape.scunning.com/) is a free textbook on these topics, and all have good YouTube video explanations."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation:\n",
        "\n",
        "Unfortunately I once again was not able to load a relevant dataset (or enough of it, including the metadata) into this file. If I was, I would have analyzed it and interpreted the according regressions here."
      ],
      "metadata": {
        "id": "XYdl7jzhVgyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import data\n",
        "import os\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiNgJyD5snhY",
        "outputId": "15eec132-56cd-4549-f9f9-472f588d6e6a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/My Drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bYsuGnsKslq",
        "outputId": "8d1970b7-7984-4034-d46a-c7bc628b27fc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loadcorpus(targetdir, endpoint=False):\n",
        "    k=2 # Number of files to be load\n",
        "    \n",
        "    break_flag = False\n",
        "    texts = pd.DataFrame()\n",
        "\n",
        "    count = 20\n",
        "    for file1 in os.listdir(targetdir):\n",
        "        file1name = os.fsdecode(file1)\n",
        "        if file1name.startswith('text'):\n",
        "            zfile = zipfile.ZipFile(targetdir + '/' + file1)\n",
        "            for file2 in zfile.namelist():\n",
        "                file2name = os.fsdecode(file2)\n",
        "                #optional endpoint if you only want a portion of the NOW corpus\n",
        "                if file2name == endpoint:\n",
        "                    break_flag = True\n",
        "                    break\n",
        "                print(file2name)\n",
        "                data = pd.read_fwf(zfile.open(f'{file2name}'),colspecs=[(2,10),(11,None)],encoding='utf-8',names=['id','body'])\n",
        "                texts = texts.append(data,ignore_index=True)\n",
        "            count += 1\n",
        "            if count >= k:\n",
        "                break\n",
        "\n",
        "        if break_flag == True:\n",
        "            break\n",
        "    return texts"
      ],
      "metadata": {
        "id": "OCG5vUnItnIc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = loadcorpus('/content/drive/MyDrive/NOW')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEV8JJDUto7B",
        "outputId": "166528e8-4ec0-4f99-c0ce-fee56805cbe4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10-01-au.txt\n",
            "10-01-bd.txt\n",
            "10-01-ca.txt\n",
            "10-01-gb.txt\n",
            "10-01-gh.txt\n",
            "10-01-hk.txt\n",
            "10-01-ie.txt\n",
            "10-01-in.txt\n",
            "10-01-jm.txt\n",
            "10-01-ke.txt\n",
            "10-01-lk.txt\n",
            "10-01-my.txt\n",
            "10-01-ng.txt\n",
            "10-01-nz.txt\n",
            "10-01-ph.txt\n",
            "10-01-pk.txt\n",
            "10-01-sg.txt\n",
            "10-01-tz.txt\n",
            "10-01-us.txt\n",
            "10-01-za.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts"
      ],
      "metadata": {
        "id": "e5J4pw9bto6H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "8ce355d1-31a3-4ee8-b8f5-6e00e0f6e727"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7c620395-9951-471b-9a47-648150119868\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1335120</td>\n",
              "      <td>h&gt; Popular Stories &lt;h&gt; Local Real Estate &lt;h&gt; S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1335121</td>\n",
              "      <td>h&gt; Overview &lt;p&gt; ' Huge glass jars stood on the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1335122</td>\n",
              "      <td>h&gt; Related coverage &lt;p&gt; It 's time to spare a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1335124</td>\n",
              "      <td>p&gt; Victoria 's wild weather has moved to the e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1335127</td>\n",
              "      <td>h&gt; Pre-nup changes a boon for lawyers &lt;p&gt; For ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25675</th>\n",
              "      <td>1367142</td>\n",
              "      <td>p&gt; PROCLAIM 360 , a Nigeria-based communicatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25676</th>\n",
              "      <td>1367694</td>\n",
              "      <td>p&gt; All reader responses posted on this site ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25677</th>\n",
              "      <td>1367695</td>\n",
              "      <td>h&gt; NEWS &amp;amp; ANALYSIS &lt;h&gt; Do n't sell COPE 's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25678</th>\n",
              "      <td>1367696</td>\n",
              "      <td>p&gt; The SACP Western Cape held its PEC Lekgotla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25679</th>\n",
              "      <td>1367697</td>\n",
              "      <td>h&gt; Wireless chargers in South Africa &lt;p&gt; In la...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25680 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c620395-9951-471b-9a47-648150119868')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c620395-9951-471b-9a47-648150119868 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c620395-9951-471b-9a47-648150119868');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            id                                               body\n",
              "0      1335120  h> Popular Stories <h> Local Real Estate <h> S...\n",
              "1      1335121  h> Overview <p> ' Huge glass jars stood on the...\n",
              "2      1335122  h> Related coverage <p> It 's time to spare a ...\n",
              "3      1335124  p> Victoria 's wild weather has moved to the e...\n",
              "4      1335127  h> Pre-nup changes a boon for lawyers <p> For ...\n",
              "...        ...                                                ...\n",
              "25675  1367142  p> PROCLAIM 360 , a Nigeria-based communicatio...\n",
              "25676  1367694  p> All reader responses posted on this site ar...\n",
              "25677  1367695  h> NEWS &amp; ANALYSIS <h> Do n't sell COPE 's...\n",
              "25678  1367696  p> The SACP Western Cape held its PEC Lekgotla...\n",
              "25679  1367697  h> Wireless chargers in South Africa <p> In la...\n",
              "\n",
              "[25680 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loadmetadata(targetdir):\n",
        "    metadata = pd.DataFrame()\n",
        "    for file1 in os.listdir(targetdir):\n",
        "        file1name = os.fsdecode(file1)\n",
        "        print(file1name)\n",
        "        if file1name.startswith('now_sources') or file1name.startswith('sources'):\n",
        "            zfile = zipfile.ZipFile(targetdir + '/' + file1)\n",
        "            for file2 in zfile.namelist():\n",
        "                file2name = os.fsdecode(file2)\n",
        "                print(file2name)\n",
        "                data = pd.read_csv(zfile.open(f'{file2name}'),sep='\\t',error_bad_lines=False,engine='python',encoding='latin1',names=['id','length','date','country','publisher','url','snippet'])\n",
        "                metadata = metadata.append(data,ignore_index=True)\n",
        "    return metadata"
      ],
      "metadata": {
        "id": "Myw-cjf6tuTw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata = loadmetadata('/content/drive/MyDrive/NOW')"
      ],
      "metadata": {
        "id": "RRky6tLGtwiM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9eb91979-1e55-44b4-e62e-dbf007a98449"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_10-01-kus.zip\n",
            "text_10-02-kvz.zip\n",
            "text_10-03-ovi.zip\n",
            "text_10-04-laq.zip\n",
            "text_10-05-wbb.zip\n",
            "text_10-06-bwq.zip\n",
            "text_10-07-uek.zip\n",
            "text_10-08-lqd.zip\n",
            "text_10-09-udn.zip\n",
            "text_10-10-nln.zip\n",
            "text_10-11-weq.zip\n",
            "text_10-12-ixv.zip\n",
            "text_11-01-pct.zip\n",
            "text_11-02-keb.zip\n",
            "text_11-03-lup.zip\n",
            "text_11-04-fpt.zip\n",
            "text_11-05-gbc.zip\n",
            "text_11-06-hld.zip\n",
            "text_11-07-mpk.zip\n",
            "text_11-08-lag.zip\n",
            "text_11-09-ptj.zip\n",
            "text_11-10-qsy.zip\n",
            "text_11-11-rst.zip\n",
            "text_11-12-dxg.zip\n",
            "text_12-01-jgs.zip\n",
            "text_12-02-eig.zip\n",
            "text_12-03-hge.zip\n",
            "text_12-04-qzl.zip\n",
            "text_12-05-qvg.zip\n",
            "text_12-06-ury.zip\n",
            "text_12-07-jbh.zip\n",
            "text_12-08-apx.zip\n",
            "text_12-09-qxc.zip\n",
            "text_12-10-fim.zip\n",
            "text_12-11-ysq.zip\n",
            "text_12-12-fbe.zip\n",
            "text_13-01-lii.zip\n",
            "text_13-02-fwy.zip\n",
            "text_13-03-zxv.zip\n",
            "text_13-04-vzr.zip\n",
            "text_13-05-skm.zip\n",
            "text_13-06-rak.zip\n",
            "text_13-07-mht.zip\n",
            "text_13-08-ofo.zip\n",
            "text_13-09-ibd.zip\n",
            "text_13-10-zpv.zip\n",
            "text_13-11-vwg.zip\n",
            "text_13-12-yny.zip\n",
            "text_14-01-jhx.zip\n",
            "text_14-02-fbh.zip\n",
            "text_14-03-mps.zip\n",
            "text_14-04-oki.zip\n",
            "text_14-05-cwh.zip\n",
            "text_14-06-glg.zip\n",
            "text_14-07-oul.zip\n",
            "text_14-08-gri.zip\n",
            "text_14-09-hkl.zip\n",
            "text_14-10-alo.zip\n",
            "text_14-11-tlv.zip\n",
            "text_14-12-dik.zip\n",
            "text_15-01-oam.zip\n",
            "text_15-02-xnd.zip\n",
            "text_15-03-dhu.zip\n",
            "text_15-04-qci.zip\n",
            "text_15-05-xzr.zip\n",
            "text_15-06-jhb.zip\n",
            "text_15-07-ztm.zip\n",
            "text_15-08-orq.zip\n",
            "text_15-09-jex.zip\n",
            "text_15-10-fxo.zip\n",
            "text_15-11-xje.zip\n",
            "text_15-12-bjr.zip\n",
            "text_16-01-yxh.zip\n",
            "text_16-02-iuq.zip\n",
            "text_16-03-sls.zip\n",
            "text_16-04-ovb.zip\n",
            "text_16-05-bvk.zip\n",
            "text_16-06-uda.zip\n",
            "text_16-07-qxx.zip\n",
            "text_16-08-pcg.zip\n",
            "text_16-09-bmb.zip\n",
            "text_16-10-ykw.zip\n",
            "text-16-11.zip\n",
            "sources-16-11.zip\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m             \u001b[0mendrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_EndRecData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m_EndRecData\u001b[0;34m(fpin)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfpin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m     if (len(data) == sizeEndCentDir and\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1258\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1259\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1322\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-8896e5792341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadmetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/NOW'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-86d421275885>\u001b[0m in \u001b[0;36mloadmetadata\u001b[0;34m(targetdir)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile1name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfile1name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'now_sources'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfile1name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sources'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mzfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetdir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfile2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mfile2name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfsdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1292\u001b[0m             \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fpclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m_fpclose\u001b[0;34m(self, fp)\u001b[0m\n\u001b[1;32m   1937\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fileRefCnt\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1938\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fileRefCnt\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filePassed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1939\u001b[0;31m             \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metadata"
      ],
      "metadata": {
        "id": "phZyYH-wt2DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged = pd.merge(metadata,texts,on='id',how='inner')"
      ],
      "metadata": {
        "id": "PGOaB87Ht2qE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "cb0bbea2-ecfc-475b-928c-171bbf8c0875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-33805cb68d98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmerged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     )\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1107\u001b[0m                         \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m                         \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1777\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'id'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged"
      ],
      "metadata": {
        "id": "IwAHqa_tt6ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged.to_csv('/content/drive/MyDrive/NOW')"
      ],
      "metadata": {
        "id": "Fhepu6oit7Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ktlDwbJTqj0e"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71l6yoigQpVm"
      },
      "source": [
        "## Splitting training and test text\n",
        "Above, we used a number of external measures of text, meaning that the measures were developed without any influence from this dataset. For annotations, it was Mechanical Turk workers measuring the text. For length, that is a mathematical count of characters. For sentiment, it was from a BERT model not trained on the Internet Arguments Corpus.\n",
        "\n",
        "This is not always the case. Consider if we want to make a measure of the text based on topic modeling. We build an LDA topic model of these comments, then we select an appealingly relevant topic and measure what number of words from Topic 1 each comment uses. Can we put that measure in the regression? We could, but it would lead to a biased estimate of the true effect size because our measure is no longer external or exogenous. The measure and model are double-dipping from the same textual information. This is important to keep in mind for your final projects, and for a more thorough explanation and justification, you can read more about this in [Egami et al. 2018](https://arxiv.org/pdf/1802.02163.pdf).\n",
        "\n",
        "One approach to this in the Internet Arguments Corpus would be to build measures with the `pairs` that were not also `triples`. Sometimes we have excess data like this that is similar enough to our regression data, which we can use without reducing our regression sample size. For example, you could abductively generate a keyword-count measure like \"argumentativeness\" or \"thoughtfulness\" from non-triple pairs that isn't already in the annotations, and then count the keywords in the triples. You could develop an LDA model or word embedding measurement on some of the data, and the use it to establish an inferential relationship on the rest of the data. This would avoid contamination."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5fHYmhpQpVm"
      },
      "source": [
        "## <font color=\"red\">*Exercise 3*</font>\n",
        "\n",
        "<font color=\"red\">Propose a measure you could generate to fill in or improve upon the simple causal model you proposed above and how you would split the data (e.g., a % of your main data, a separate-but-informative dataset). You do not have to produce the measure.\n",
        "    \n",
        "<font color=\"red\">***Stretch*** (not required): Produce the measure and integrate it into your statistical analysis. This could be a great approach for your final project!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "An interesting addendum would be to do analyze my question as a matched-pairs causal argument. For example, one could match members of parliament from East and West German districts that are similar to one another with the only difference being that one is in the East, the other in the West. I'm not sure how in such an instance one could split the data though."
      ],
      "metadata": {
        "id": "LLg-JUOlYA-O"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCOnmUGZQpVm"
      },
      "source": [
        "# Text as mediator\n",
        "\n",
        "What if text is instead the _mediator_, meaning it is effected by the teatment and effects the outcome? (A moderator influences the relationship a treatment has on the outcome. This figure from [Bhandari](https://www.scribbr.com/methodology/mediator-vs-moderator/) concisely shows the difference\n",
        "\n",
        "<img src=\"https://cdn.scribbr.com/wp-content/uploads/2021/03/mediator-and-moderator-variables.png\" alt=\"https://cdn.scribbr.com/wp-content/uploads/2021/03/mediator-and-moderator-variables.png\" style=\"width:500px\">\n",
        "The moderating impact of a variable can simply be captured by in/excluding the variable alongside the purported cause of interest.)\n",
        "\n",
        "Let's briefly return to the Internet Arguments Corpus triples and model the effect of the first comment (\"quote\") on the third comment (\"response2\") mediated by the second comment (\"response1\"). Unfortunately we don't have Turker annotations for the first comment, but we can propose a simple mediation model for the propogation of comment length from first to second to third. In other words: _Is there a causal chain of comment length through a conversation?_\n",
        "\n",
        "A two-step mediation model consists of two linear models, one for each step. Let's create length_q and sentiment_q variables for our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUhulhkyQpVn"
      },
      "outputs": [],
      "source": [
        "triples['length_q'] = triples['quote'].apply(lambda x: len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sy7J5cg4QpVn"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "triples['sentiment_q'] = triples['quote'].apply(lambda x: sentiment(x[:512])[0]['score'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG86l3EmQpVn"
      },
      "source": [
        "To run this analysis, statsmodel (sm) has a convenient `Mediation` module that takes in two linear models and outputs a mediation model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkGxt4FJQpVn"
      },
      "outputs": [],
      "source": [
        "# Mediation analysis\n",
        "y = triples['length_r1']\n",
        "X_cols = ['sentiment_q','length_q']\n",
        "X = sm.add_constant(triples[X_cols])\n",
        "mediator_model = sm.OLS(y,X)\n",
        "\n",
        "# For the second step of the mediation model, we can add in other predictors.\n",
        "y = triples['length_r2']\n",
        "X_cols = ['sentiment_q','length_q','fact-feeling_r1','nicenasty_r1','sarcasm_r1','length_r1','sentiment_r1']\n",
        "X = sm.add_constant(triples[X_cols])\n",
        "outcome_model = sm.OLS(y,X)\n",
        "\n",
        "med = Mediation(outcome_model=outcome_model, mediator_model=mediator_model,\n",
        "                exposure='length_q', mediator='length_r1').fit()\n",
        "med.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOY2fbaJQpVo"
      },
      "source": [
        "It looks like the Average Causal Mediated Effect (ACME) is not significantly different from zero, but the Average Direct Effect (ADE) is. This suggests that the true causal relationship here is more likely:\n",
        "\n",
        "_length_q -> length_r2_\n",
        "\n",
        "than\n",
        "\n",
        "_length_q -> length_r1 -> length_r2_\n",
        "\n",
        "What do you think explains that relationship?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omCLt33WQpVo"
      },
      "source": [
        "## <font color=\"red\">*Exercise 4*</font>\n",
        "\n",
        "<font color=\"red\">Propose a mediation model related to the simple causal model you proposed above (ideally on the dataset you're using for your final project). If you have measures for each variable in the model, run the analysis: You can just copy the \"Mediation analysis\" cell above and replace with your variables. If you do not have measures, do not run the analysis, but be clear as to the effect(s) you would like to estimate and the research design you would use to test them."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A mediation model, in my context, would be highly interesting, and is actually something I've previously applied to questions surrounding politics in East Germany. In this particular scenario, I would amend my previous hypotheses with a mediation. Recall my predictions from question 1:\n",
        "\n",
        "First prediction: I hypothesize that the party identity of a given member of the German Bundestag predicts the sentiment of a speech if the speech is about East Germany or the former German Democratic Republic.\n",
        "\n",
        "Second prediction: Relatedly, I hypothesize that the type and location of electoral district of a given member of the Bundestag predicts the sentiment of a speech if the speech is about East Germany or the former German Democratic Republic.\n",
        "\n",
        "\n",
        "An interesting mediation analysis, in my view, would be to see if the components of the second prediction (i.e. type and location of electoral district) significantly mediate the effects of party identity on a member's sentiment in speeches about the GDR or East Germany."
      ],
      "metadata": {
        "id": "ugXQsYcMZVNh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvjJP65-QpVo"
      },
      "source": [
        "# Text as confounder\n",
        "The causal effect we're interested in estimating might not be our causal relationship of interest. Instead, it could be another variable that affects both our treatment and outcome, known as a _confounder_. Recall the [Keith et al. 2020](https://aclanthology.org/2020.acl-main.474.pdf) figure showing the role of a confounder.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/UChicago-Computational-Content-Analysis/Homework-Notebooks/main/week-6/img/causal_diagram.png\" alt=\"https://raw.githubusercontent.com/UChicago-Computational-Content-Analysis/Homework-Notebooks/main/week-6/img/causal_diagram.png\" style=\"width:500px\">\n",
        "\n",
        "Why do we need to control for confounders? If we didn't, we might correctly find that the treatment and outcome are correlated, but rather than one causing the other, they could both be caused by a third variable. For example, if we are studying the effect of the journal a paper is published in on the citations of the paper, we may be worried that the text of the article affects both whether it is published by the journal and whether people cite it.\n",
        "\n",
        "The factors we controlled for in the Internet Arguments Corpus could be seen as confounders, but there are also specific methods to control for text confounders. As an example, we will walk through the method proposed by [Pryzant et al. (2018)](https://nlp.stanford.edu/pubs/pryzant2018lexicon.pdf).\n",
        "\n",
        "Say that we want to know the effect of product descriptions on product popularity. If I'm a shoe seller, how should I describe my shoes to maximize sales? Suppose I have data on sales of other shoes and want to learn from it:\n",
        "\n",
        "| Description   | Brand   | Sales |\n",
        "|---------------|---------|-------|\n",
        "| buy shoes !     | addidas | 15    |\n",
        "| fresh nike shoes !  | nike    | 35    |\n",
        "| nice nike shoes ! | nike    | 17    |\n",
        "\n",
        "It looks like \"nike\" is associated with higher sales! But that doesn't help me very much because I can't just advertise my shoes as Nikes. That would be incorrect and illegal (false advertising). What if we could build a lexicon of words like \"nike\" associated with certain brands and control for that in my analysis? We could then identify brand-agnostic words like \"fresh\" that have the causal effect of interest. This is the approach by Pryzant et al.\n",
        "\n",
        "Instead of shoes, we're going to work with Consumer Financial Protection Bureau (CFPB) complaints. When US residents complain about financial products (e..g, mortgages, credit reports), the CFPB sometimes handles these on a \"timely basis (<15 days)\" and sometimes not. If you want to submit a complaint, how should you word it so you get a timely response? We want to control for the differences in wording that result from different products to identify the causal effect of interest. For example, if saying \"mortgage\" is associated with a timely response, that doesn't mean you should throw \"mortgage\" into your complaint about a credit report.\n",
        "\n",
        "Let's download the data and construct a Pandas DataFrame!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pP0X5uLHQpVo"
      },
      "outputs": [],
      "source": [
        "url = 'https://files.consumerfinance.gov/ccdb/complaints.csv.zip'\n",
        "\n",
        "req = requests.get(url)\n",
        "\n",
        "filename = url.split('/')[-1]\n",
        "with open(filename,'wb') as output_file:\n",
        "    output_file.write(req.content)\n",
        "print('Downloaded file: ' + url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5t6d_N9QpVo"
      },
      "outputs": [],
      "source": [
        "zipfile.ZipFile('complaints.csv.zip').extractall('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cMRA3zwQpVp"
      },
      "outputs": [],
      "source": [
        "complaints = pd.read_csv('complaints.csv')\n",
        "complaints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dzvfAqiQpVp"
      },
      "outputs": [],
      "source": [
        "complaints['timely'] = complaints['Timely response?'].apply(lambda x: 1 if (x == 'Yes') else 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kybdL70RQpVp"
      },
      "source": [
        "Very interesting! So our goal is to build a lexicon associated with the `Product` column in order to better identify the effect of wording choices in `Consumer complaint narrative` on whether `Timely response?` is `Yes` or `No`. Fortunately Pryzant et al. made a very convenient package to build such a lexicon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPWYiWmDQpVp"
      },
      "outputs": [],
      "source": [
        "# !pip install causal-attribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjdGD_kBQpVp"
      },
      "outputs": [],
      "source": [
        "import causal_attribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFIXwA-4QpVp"
      },
      "source": [
        "We will use their function called `causal_attribution.score_vocab()`. This takes as input a vocabulary of words that we want to assess, the CSV file with data, and a dictionary that tells the function which column of the CSV is your input, your control, and your intended prediction. What vocabulary should we use? Let's put in some words related to the `Product` column as well as some words that may causally effect `Timely response?`. You can also run it on much larger vocabularies (Pryzant et al. use 2000), but it will take more time to compute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZkGVI4rQpVp"
      },
      "outputs": [],
      "source": [
        "product_num = complaints['Product'].value_counts()\n",
        "product_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxFl64oUQpVp"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "importance_scores = causal_attribution.score_vocab(\n",
        "    vocab=[\n",
        "           # Words I expect to be associated with Product\n",
        "           'credit','loan','bank','card','mortgage','transfer','account','money','virtual','paypay','prepaid','lease',\n",
        "           # Words I expect to be associated with timeliness\n",
        "           'fraud','crime','urgent','please','help',\n",
        "           # Words I expect to not be associated with either\n",
        "           'bad','good','help','thank','why','husband','wife','family'\n",
        "          ],\n",
        "    csv='complaints.csv',\n",
        "    delimiter=\",\",\n",
        "    name_to_type={\n",
        "        'Consumer complaint narrative': 'input',\n",
        "        'Product': 'control',\n",
        "        'Timely response?': 'predict',\n",
        "    })\n",
        "\n",
        "importance_scores['Timely response?']['Yes']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO8rqR5iQpVp"
      },
      "source": [
        "That output isn't that intuitive, but in theory, higher scores correspond to words that better explain `Timely response?` when controlling for `Product`. This suggests that saying `mortgage` is actually a good way to get a timely response even if your complaint isn't about a mortgage! That's interesting. As with other causal inference approaches, we can take a closer look at our data to help explain the results. For example, let's look at whether the `Mortgage` `Product` category had a very high timeliness rate. \n",
        "\n",
        "You can ignore 'UNK' and 'PAD', but if you're curious, 'UNK' refers to all tokens that are in the corpus but not in the vocab, and 'PAD' refers to padding added to texts to make their length consistent—-this is common in neural networks because the network is usually designed with a certain input length, so you need to add padding tokens if the input is shorter. You will see padding very frequently in other text-based neural networks and should keep it in mind when building your own in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwNnfTK1QpVq"
      },
      "outputs": [],
      "source": [
        "product_timelies = complaints.groupby('Product').agg({'timely': 'sum'}).sort_values(by=['timely'],ascending=False)\n",
        "pcts = product_timelies.divide(product_num,axis=0).sort_values(by=['timely'],ascending=False)\n",
        "pcts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GAGA9aeQpVq"
      },
      "source": [
        "Mortgage is in the middle of the pack, so it doesn't seem like mortgages in themselves are extremely likely to be responded to in a timely manner. This is something you can explore in more detail if you have time and interest. For example, you can check for which products the word `mortgage` is most strongly associated with timeliness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjsAJeB_QpVq"
      },
      "source": [
        "## <font color=\"red\">*Exercise 5*</font>\n",
        "\n",
        "<font color=\"red\">Propose a confounder in your final project data that could be controlled for using the method of Pryzant et al. Generate an appropriate CSV file and run it on some vocabulary in your corpus. If you have no such confounder available for your final project, you can use `complaints.csv` with a new vocabulary or for different variables (e.g., `Sub-product`, `Company`) or you can further explore the interesting case of `mortgage`. Also keep in mind the [ConvoKit datasets](https://convokit.cornell.edu/documentation/datasets.html). In any case, be sure to interpret the results. What does the output of `causal_attribution.score_vocab()` mean in your context?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A confounding variable, in my view, is the time at which a speech is given and the political contexts of the time. People in 1990, the year of the reunification, are naturally going to have a different sentiment with which they talk about the GDR (that only recently ceased to exist) in comparison to speeches given later. Similarly, other political events (e.g. the Russian invasion of Georgia in 2009) might propose confounding factors that are difficult to account for."
      ],
      "metadata": {
        "id": "EzESUAFfaBYR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l91q0RsYQpVq"
      },
      "source": [
        "# \"Causally sufficient\" embedding and topic models\n",
        "Our final example of causal inference with text is from Victor Veitch (now a statistics and CS professor at UChicago), Sridhhar, and Blei. You may recall Blei as the lead developer of LDA, HDP, and Dynamic topic models, among other amazing contributions to content analysis.\n",
        "\n",
        "Their 2020 paper, [\"Adapting Text Embeddings for Causal Inference\"](https://arxiv.org/abs/1905.12741), proposes reducing the dimensions of contextual text embeddings (from BERT) in a manner that preserves causally relevant text signals. For example: \"Does adding a theorem to a paper affect its chance of acceptance?\" We can apply supervised dimensionality reduction to make the embedding easier to analyze (i.e., lower dimension) but preserve information about whether theorems are present. Similar to Pryzant et al., Veitch et al. have a great [GitHub respository](https://github.com/blei-lab/causal-text-embeddings) with the data and code for their paper, and their dataset of computer science papers, PeerRead, has its own great [repo](https://github.com/allenai/PeerRead).\n",
        "\n",
        "Their code is somewhat too hefty and farflung for this assignment, but for your future research, keep in mind that you can adjust your textual objects (e.g., keyword counts, topic models, word embeddings) for causal models. Bringing together unsupervised machine learning with causal inference is an exciting and rapidly developing field!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0X0ZSb4QpVq"
      },
      "source": [
        "## <font color=\"red\">*Exercise 6*</font>\n",
        "\n",
        "<font color=\"red\">Pick one other paper on causal inference with text from the [\"Papers about Causal Inference and Language\n",
        "\" GitHub repository](https://github.com/causaltext/causal-text-papers). Write at least three sentences summarizing the paper and its logic of design in your own words.\n",
        "    \n",
        "<font color=\"red\">***Stretch*** (not required): Skim a few more papers. The causal world is your textual oyster!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In \"When do Words Matter? Understanding the Impact of Lexical Choice on\n",
        "Audience Perception using Individual Treatment Effect Estimation\", Wang and Culotta propose a method to infer the causal effect of lexical choice on the perception of a given sentence. The authors utilize two different approaches: the first relies on algorithms rooted in quasi-experimental designs and used to understand individual treatment effects, while the second set of algorithms approaches understanding treatment effects as a classification problem. The authors then test this approach on three different datasets, and find that the approach works well."
      ],
      "metadata": {
        "id": "2EfLif73S7v6"
      }
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "kpekkip - 6-Prediction-and-Causal-Inference.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}